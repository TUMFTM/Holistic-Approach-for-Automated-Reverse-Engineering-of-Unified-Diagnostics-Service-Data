{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Categorical Signals\n",
    "\n",
    "Notebook used to evaluate categorical signal data.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from revcan.reverse_engineering.models.experiment import Extern_Signal, Value, Experiment, Signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from colorama import Fore, Style\n",
    "\n",
    "import revcan.reverse_engineering.models.NNs.SignalMatchingNN_CategoricalSignals as smnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set experiment\n",
    "\n",
    "Set the experiment name and folder of the combined experiment file (containing all measurements for an experiment including ground truth values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set name and folder of experiment\n",
    "experiment_name = \"experiment_non_constant_signals\"\n",
    "\n",
    "experiment_folder = \"../../data/experiments/car/ride_height/2025-06-02_17_25_17\"\n",
    "\n",
    "\n",
    "Path(experiment_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "experiment_file = os.path.join(experiment_folder, f\"{experiment_name}.json\")\n",
    "experiment = Experiment.load(experiment_file)\n",
    "\n",
    "!python ../scripts_for_doip_new/display_experiment_metadata.py --experiment_file_path \"{experiment_file}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Training\n",
    "\n",
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "full_data = smnn.load_data(experiment)\n",
    "print(\"full_data Shape:\", full_data.shape)\n",
    "print(\"Remaining NaN values:\", full_data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = smnn.custom_train_test_split(full_data)\n",
    "print(\"Train Shape:\", train_df.shape)\n",
    "print(\"Test Shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Includes one-hot encoding and splitting the data into one data frame per signal.\n",
    "This is done for the train and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Values of Train set\n",
    "signal_data_train = smnn.split_df_by_signal(train_df)\n",
    "skipped_signals_train = 0\n",
    "\n",
    "for signal_key, df in signal_data_train.items():\n",
    "    try:\n",
    "        df = smnn.expand_signal_df(df)\n",
    "        df = smnn.one_hot_encode_ground_truth(df) # One-Hot Encoding\n",
    "        signal_data_train[signal_key] = df\n",
    "        print(f\"Signal {signal_key} → Shape: {df.shape}\")\n",
    "    except ValueError as e:\n",
    "        skipped_signals_train += 1\n",
    "        print(f\"\\033[91mSkipped Signal {signal_key}: {e}\\033[0m\")\n",
    "\n",
    "print(f\"Expanding of values of train set complete - Signals skipped: {skipped_signals_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Values of Test Set\n",
    "signal_data_test = smnn.split_df_by_signal(test_df)\n",
    "skipped_signals_test = 0\n",
    "\n",
    "for signal_key, df in signal_data_test.items():\n",
    "    try:\n",
    "        df = smnn.expand_signal_df(df)\n",
    "        df = smnn.one_hot_encode_ground_truth(df) # One-Hot Encoding\n",
    "        signal_data_test[signal_key] = df\n",
    "        print(f\"Signal {signal_key} → Shape: {df.shape}\")\n",
    "    except ValueError as e:\n",
    "        skipped_signals_test += 1\n",
    "        print(f\"\\033[91mSkipped Signal {signal_key}: {e}\\033[0m\")\n",
    "\n",
    "print(f\"Expanding of values of test set complete - Signals skipped: {skipped_signals_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data & Train NN per Signal\n",
    "\n",
    "The epochs, batch_size and hidden layers config can be set and modified individually.\n",
    "Activating the check_for_ambigous_signals flag, excludes signals that have a feature overlap (same value for different ground truth categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "hidden_layers_config=[16]\n",
    "check_for_ambiguous_signals = True\n",
    "\n",
    "results = {}\n",
    "models = {}\n",
    "for signal_key in signal_data_train:\n",
    "    # Check if found test data for signal\n",
    "    if signal_key not in signal_data_test:\n",
    "        print(f\"\\033[93mSkipping {signal_key} — not in test set\\033[0m\")\n",
    "        continue\n",
    "    \n",
    "    if check_for_ambiguous_signals:\n",
    "        # Check whether signal has the same byte value for more then one ground_truth class\n",
    "        if smnn.is_ambiguous_signal(signal_data_train[signal_key]):\n",
    "            print(f\"\\033[93mSkipping {signal_key} — feature overlap between classes\\033[0m\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Preprocess data\n",
    "        X_train, y_train = smnn.preprocess_signal_df(signal_data_train[signal_key])\n",
    "        X_test, y_test = smnn.preprocess_signal_df(signal_data_test[signal_key])\n",
    "\n",
    "        # Check for signals with no variance\n",
    "        if smnn.is_useless_signal(train_df) or smnn.is_useless_signal(test_df):\n",
    "            print(f\"\\033[93mSkipping {signal_key} — input features have no variation\\033[0m\")\n",
    "            continue\n",
    "\n",
    "        # Train model\n",
    "        model, metrics = smnn.train_signal_model(X_train, y_train, X_test, y_test, hidden_layers_config=hidden_layers_config, epochs=epochs,batch_size=batch_size)\n",
    "        results[signal_key] = metrics\n",
    "        models[signal_key] = model\n",
    "\n",
    "        accuracy = metrics['accuracy']\n",
    "        precision = metrics['precision']\n",
    "\n",
    "        print(f\"Trained {signal_key} → Accuracy: {accuracy:.3f}, Precision: {precision:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91mFailed {signal_key}: {e}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Models\n",
    "\n",
    "Displays the top performing DIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 50\n",
    "sorted_results = sorted(results.items(), key=lambda x: smnn.score(x[1]), reverse=True)\n",
    "\n",
    "# Header\n",
    "print(f\"{'Rank':<6} {'Signal':<20} {'Length':<8}  {'Score':<10} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for i, (signal_key, metrics) in enumerate(sorted_results[:top_n]):\n",
    "    # Signal length in bytes\n",
    "    signal_df = signal_data_train[signal_key]\n",
    "    byte_columns = [col for col in signal_df.columns if col.startswith(\"Byte_\")]\n",
    "    signal_length = len(byte_columns)\n",
    "    \n",
    "    # Get and calculate metrics\n",
    "    score = smnn.score(metrics)\n",
    "    accuracy = metrics['accuracy']\n",
    "    precision = metrics['precision']\n",
    "    recall = metrics['recall']\n",
    "    f1 = metrics['f1']\n",
    "\n",
    "    signal_str = f\"{signal_key}\"\n",
    "\n",
    "    row = f\"{i+1:<6} {signal_str:<20} {signal_length:<8} {score:<10.3f} {accuracy:<10.3f} {precision:<10.3f} {recall:<10.3f} {f1:<10.3f}\"\n",
    "\n",
    "    if accuracy == 1.0:\n",
    "        print(Fore.GREEN + row + Style.RESET_ALL)\n",
    "    else:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore below line. Used to enable Run all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"STOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Display raw train and test data for a specific signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_key = (16512, 17738)\n",
    "#signal_key = (16512,11156) # Chassis Level Paper\n",
    "#signal_key = (16398, 11527) # Chassis Level - Top candidate\n",
    "#signal_key = (16512, 801) # Chassis Level Time\n",
    "#signal_key = (16443, 646)  # Brake Pedal Activation 2\n",
    "#signal_key = (16403, 11066) # Brake Pedal Activation\n",
    "#signal_key = (16502, 2180) # Gear: No distinction between D1 and D2\n",
    "#signal_key = (16400, 4104) # Gear: Distinction between D1 and D2\n",
    "\n",
    "print(f\"Server: {signal_key[0]}, DID: {signal_key[1]}\")\n",
    "print(\"Training Set Data:\")\n",
    "signal_data_train[signal_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Server: {signal_key[0]}, DID: {signal_key[1]}\")\n",
    "print(\"Test Set Data:\")\n",
    "signal_data_test[signal_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Signal to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def export_signal_from_experiment(experiment, server_id: int, did: int, output_path: str):\n",
    "    for signal in experiment.measurements:\n",
    "        # Find selected Signal\n",
    "        if signal.serverid == server_id and signal.did.did == did:\n",
    "            records = []\n",
    "            # Append rows of data frame\n",
    "            for i in range(len(signal.values)):\n",
    "                ground_truth_gear = experiment.external_alphanumeric_measurements[0].values[i]\n",
    "                ground_truth_speed = experiment.external_measurements[0].values[i].value[0]\n",
    "                byte_values = signal.values[i].value\n",
    "                records.append([ground_truth_gear, ground_truth_speed] + byte_values)\n",
    "\n",
    "            # Build DataFrame\n",
    "            max_len = max(len(row) - 2 for row in records)\n",
    "            columns = [\"Gear\", \"Speed\"] + [f\"Byte_{i}\" for i in range(max_len)]\n",
    "            df = pd.DataFrame(records, columns=columns)\n",
    "\n",
    "            # Export\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Exported signal (Server: {server_id}, DID: {did}) to '{output_path}'\")\n",
    "            return\n",
    "\n",
    "    print(f\"ERROR: Signal with Server: {server_id}, DID: {did} not found in the experiment.\")\n",
    "\n",
    "ServerID, DID = (16502, 2204)\n",
    "csv_file = os.path.join(experiment_folder, f\"gear_signal_{ServerID}_{DID}.csv\")\n",
    "export_signal_from_experiment(experiment, server_id=ServerID, did=DID, output_path=csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter signals to keep top candidates\n",
    "\n",
    "Can be used for additional training on top candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = 0.7 # TODO: Define treshold\n",
    "\n",
    "high_score_keys = []\n",
    "for signal_key, metrics in results.items():\n",
    "    if smnn.score(metrics) >= score_threshold:\n",
    "        high_score_keys.append(signal_key)\n",
    "\n",
    "signals_to_keep = []\n",
    "for signal in experiment.measurements:\n",
    "    if (signal.serverid, signal.did.did) in high_score_keys:\n",
    "        signals_to_keep.append(signal)\n",
    "\n",
    "experiment.measurements = signals_to_keep\n",
    "\n",
    "print(f\"{len(signals_to_keep)} - signals with score ≥ {score_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save top candidates in new experiment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_file = os.path.join(experiment_folder, f\"experiment_top_candidates_nn.json\")\n",
    "experiment.save(f\"{experiment_file}\")\n",
    "!python ../scripts_for_doip_new/display_experiment_metadata.py --experiment_file_path \"{experiment_file}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "revcan-Tm9u8sAl-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
